{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "Grad-CAM.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oYm78KTykpkU"
      },
      "source": [
        "# Gradient-Weighted Class Activation Mapping (Grad-CAM) - CIFAR10"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "npTH7JrfkpkW"
      },
      "source": [
        "import numpy as np\n",
        "import time\n",
        "import os\n",
        "\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "import tensorflow_datasets as tfds\n",
        "import tensorflow as tf\n",
        "from tensorflow.python.framework import ops\n",
        "import warnings\n",
        "import logging\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "tf.get_logger().setLevel(logging.ERROR)\n",
        "\n",
        "import cv2\n",
        "from skimage import io\n",
        "from skimage.transform import resize\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "%matplotlib inline"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "siW1eeBwkpkX"
      },
      "source": [
        "## Initialization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tXQmUfVykpkY"
      },
      "source": [
        "config = {\n",
        "    'dataset_name': 'cifar10',\n",
        "    'width': 32,\n",
        "    'height': 32,\n",
        "    'num_channels': 3,\n",
        "    'num_classes': 10,\n",
        "    'dropout_rate': [0.15, 0.1],\n",
        "    'learning_rate': 1e-4,\n",
        "    'model_path': './grad_cam_model.ckpt',\n",
        "    'log_path': './grad_cam_log.csv'\n",
        "}"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-vEhfTdYkpkY"
      },
      "source": [
        "# Data Preparation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MOICmfYJkpkY"
      },
      "source": [
        "def normalize(x):\n",
        "    # normalize data\n",
        "    x = x/255.0\n",
        "    return x.reshape((-1, config['height'], config['width'], config['num_channels']))"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W7SCFfBmkpkZ"
      },
      "source": [
        "def get_one_hot(label):\n",
        "    # convert label to one-hot encoding\n",
        "    label = label.reshape(-1, 1)\n",
        "    encoder = OneHotEncoder(categories = [range(config['num_classes'])])\n",
        "    encoder.fit(label)\n",
        "    return encoder.transform(label).toarray()"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uDDYpTDEkpkZ"
      },
      "source": [
        "def get_data(batch_size):\n",
        "    # get both train and test data\n",
        "    dataset, info = tfds.load(name = config['dataset_name'], with_info = True)\n",
        "    labels = info.features['label'].names\n",
        "\n",
        "    dataset_train_size = info.splits['train'].num_examples\n",
        "    dataset_test_size = info.splits['test'].num_examples\n",
        "\n",
        "    dataset_train = dataset['train'].repeat().shuffle(1024).batch(batch_size)\n",
        "    dataset_test = dataset['test'].repeat().shuffle(1024).batch(batch_size)\n",
        "    dataset_train = dataset_train.prefetch(tf.data.experimental.AUTOTUNE)\n",
        "    dataset_test = dataset_test.prefetch(tf.data.experimental.AUTOTUNE)\n",
        "\n",
        "    return (dataset_train, dataset_test), (dataset_train_size, dataset_test_size), labels"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KfN0cbQwkpkZ"
      },
      "source": [
        "# Build Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LftKNTxvkpka"
      },
      "source": [
        "def model(x, dropout_rate, print_summary = True):\n",
        "    # build CNN model\n",
        "    with tf.variable_scope('model_cnn', reuse = False) as scope:\n",
        "        x_t = tf.transpose(x, [0, 3, 1, 2]) # NHWC to NCHW\n",
        "\n",
        "        # block 1\n",
        "        conv1 = tf.layers.conv2d(x_t, 32, [5, 5],\n",
        "                                 strides = [1, 1],\n",
        "                                 padding = 'same',\n",
        "                                 data_format = 'channels_first',\n",
        "                                 name ='conv1')\n",
        "        relu1 = tf.nn.relu(conv1, name = 'relu1')\n",
        "        pool1 = tf.layers.max_pooling2d(relu1, [2, 2],\n",
        "                                        strides = [2, 2],\n",
        "                                        padding = 'valid',\n",
        "                                        data_format = 'channels_first',\n",
        "                                        name = 'pool1')\n",
        "        # block 2\n",
        "        conv2 = tf.layers.conv2d(pool1, 64, [3, 3],\n",
        "                                 strides = [1, 1],\n",
        "                                 padding = 'same',\n",
        "                                 data_format = 'channels_first',\n",
        "                                 name = 'conv2')\n",
        "        relu2 = tf.nn.relu(conv2, name = 'relu2')\n",
        "        pool2 = tf.layers.max_pooling2d(relu2, [2, 2],\n",
        "                                        strides = [2, 2],\n",
        "                                        padding = 'valid',\n",
        "                                        data_format = 'channels_first',\n",
        "                                        name = 'pool2')\n",
        "        # block 3\n",
        "        conv3 = tf.layers.conv2d(pool2, 128, [3, 3],\n",
        "                                 strides = [1, 1],\n",
        "                                 padding = 'same',\n",
        "                                 data_format = 'channels_first',\n",
        "                                 name = 'conv3')       \n",
        "        relu3 = tf.nn.relu(conv3, name = 'relu3')\n",
        "        pool3 = tf.layers.max_pooling2d(relu3, [2, 2],\n",
        "                                        strides = [2, 2],\n",
        "                                        padding = 'valid',\n",
        "                                        data_format = 'channels_first',\n",
        "                                        name = 'pool3')\n",
        "        # block 4\n",
        "        conv4 = tf.layers.conv2d(pool3, 256, [2, 2],\n",
        "                                 strides = [1, 1],\n",
        "                                 padding = 'same',\n",
        "                                 data_format = 'channels_first',\n",
        "                                 name = 'conv4')\n",
        "        relu4 = tf.nn.relu(conv4, name = 'relu4')\n",
        "        pool4  = tf.layers.max_pooling2d(relu4, [2, 2],\n",
        "                                         strides = [2, 2],\n",
        "                                         padding = 'valid',\n",
        "                                         data_format = 'channels_first',\n",
        "                                         name = 'pool4')\n",
        "        # block 5\n",
        "        conv5 = tf.layers.conv2d(pool4, 256, [2, 2],\n",
        "                                 strides = [1, 1],\n",
        "                                 padding = 'same',\n",
        "                                 data_format = 'channels_first',\n",
        "                                 name = 'conv5')\n",
        "        relu5 = tf.nn.relu(conv5, name = 'relu5')\n",
        "        pool5  = tf.layers.max_pooling2d(relu5, [2, 2],\n",
        "                                         strides = [2, 2],\n",
        "                                         padding = 'valid',\n",
        "                                         data_format = 'channels_first',\n",
        "                                         name = 'pool5')\n",
        "        dropout5 = tf.layers.dropout(pool5, dropout_rate[0], name = 'dropout5')\n",
        "\n",
        "        # block 6\n",
        "        flatten_length = dropout5.get_shape().as_list()[1] * \\\n",
        "                         dropout5.get_shape().as_list()[2] * \\\n",
        "                         dropout5.get_shape().as_list()[3]\n",
        "\n",
        "        flatten6 = tf.reshape(dropout5, [-1, flatten_length])\n",
        "        fc6 = tf.layers.dense(flatten6, 512, name = 'fc6')\n",
        "        relu6 = tf.nn.relu(fc6, name = 'relu6')\n",
        "\n",
        "        # block 7\n",
        "        fc7 = tf.layers.dense(relu6, 128, name = 'fc7')\n",
        "        relu7 = tf.nn.relu(fc7, name = 'relu7')\n",
        "        dropout7 = tf.layers.dropout(relu7, dropout_rate[1], name = 'dropout7')\n",
        "\n",
        "        # block 8\n",
        "        fc8 = tf.layers.dense(dropout7, config['num_classes'], name = 'fc8')\n",
        "        output = tf.nn.softmax(fc8, name = 'output')\n",
        "    if print_summary:\n",
        "        print('model summary:\\n ' \\\n",
        "              'Conv1: %s\\n Pool1: %s\\n Conv2: %s\\n Pool2: %s\\n' \\\n",
        "              'Conv3: %s\\n Pool3: %s\\n Conv4: %s\\n Pool4: %s\\n' \\\n",
        "              'Conv5: %s\\n Pool5: %s\\n Fc6: %s\\n'\\\n",
        "              'Fc7: %s\\n Fc8: %s\\n' %(conv1.get_shape(), pool1.get_shape(),\n",
        "                                      conv2.get_shape(), pool2.get_shape(),\n",
        "                                      conv3.get_shape(), pool3.get_shape(),\n",
        "                                      conv4.get_shape(), pool4.get_shape(),\n",
        "                                      conv5.get_shape(), pool5.get_shape(),\n",
        "                                      fc6.get_shape(), fc7.get_shape(),\n",
        "                                      fc8.get_shape()))\n",
        "\n",
        "    return [conv1, conv2, conv3, conv4, conv5], fc8, output"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F62npMYBkpkb"
      },
      "source": [
        "def loss_accuracy(prob, logits, labels):\n",
        "    # softmax loss and accurary\n",
        "    with tf.variable_scope('Loss_Acc', reuse = False) as scope:\n",
        "        loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits = logits,\n",
        "                                                                      labels = labels))\n",
        "        correct_pred = tf.equal(tf.argmax(prob, 1), tf.argmax(labels, 1))\n",
        "        acc = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
        "\n",
        "        return loss, acc"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V-oLispekpkc"
      },
      "source": [
        "def optimizer(loss, learning_rate):\n",
        "    # ADAM optimizer\n",
        "    with tf.variable_scope('Optimizer', reuse = False) as scope:\n",
        "        extra_update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
        "        with tf.control_dependencies(extra_update_ops):\n",
        "            all_vars = tf.trainable_variables()\n",
        "            model_vars = [var for var in all_vars if var.name.startswith('model_cnn')]\n",
        "            optimizer = tf.train.AdamOptimizer(learning_rate).minimize(loss,\n",
        "                                                                       var_list = model_vars)\n",
        "            return optimizer"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hSbvZF_Ikpkc"
      },
      "source": [
        "def get_placeholders_tensors(target_layer_index = -1):\n",
        "    # get model's placeholders and tensors\n",
        "    # target_layer_index is the index of the conv layer\n",
        "    x = tf.placeholder(tf.float32, name = 'x', shape = [None,\n",
        "                                                        config['height'],\n",
        "                                                        config['width'],\n",
        "                                                        config['num_channels']])\n",
        "    y = tf.placeholder(tf.float32, name = 'label', shape = [None,\n",
        "                                                            config['num_classes']])\n",
        "    dropout_rate = tf.placeholder(tf.float32, name = 'dropout_rate')\n",
        "\n",
        "    connvs, logits, probs = model(x, dropout_rate, print_summary = True)\n",
        "    loss, acc  = loss_accuracy(probs, logits, y)\n",
        "\n",
        "    optim = optimizer(loss, config['learning_rate'])\n",
        "\n",
        "    grad_cam = Grad_CAM(connvs[target_layer_index], logits, x, y)\n",
        "\n",
        "    placeholders_tensors = {'x': x,\n",
        "                            'y': y,\n",
        "                            'dropout_rate': dropout_rate,\n",
        "                            'optimizer': optim,\n",
        "                            'probs': probs,\n",
        "                            'loss': loss,\n",
        "                            'acc': acc,\n",
        "                            'grad_cam': grad_cam}\n",
        "    return placeholders_tensors"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EnN4_uR8kpkd"
      },
      "source": [
        "# Grad-CAM and Visualisation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xDValL2akpkd"
      },
      "source": [
        "def Grad_CAM(conv_layer, logits, x, y):\n",
        "    # gradient-weighted activation mapping (Grad_CAM) for visualisation\n",
        "    with tf.variable_scope('Grad_CAM', reuse = False) as scope:\n",
        "        y_c = tf.reduce_sum(tf.multiply(logits, y), axis = 1)\n",
        "        conv_layer_grad = tf.gradients(y_c, conv_layer)[0] # 0: weight, 1: bias\n",
        "        alpha = tf.reduce_mean(conv_layer_grad, axis = (2, 3)) # feature map importance\n",
        "        linear_combination = tf.multiply(tf.reshape(alpha, [-1,\n",
        "                                                            alpha.get_shape().as_list()[1],\n",
        "                                                            1, 1]), conv_layer)\n",
        "        grad_cam = tf.nn.relu(tf.reduce_sum(linear_combination, axis = 1))\n",
        "        return grad_cam"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XMS1xyO5kpkd"
      },
      "source": [
        "def get_results_for_visualization(sess, placeholders_tensors, dataset, count):\n",
        "    # get images, grad_cams, and predicated probabilites\n",
        "    iterator = dataset.make_one_shot_iterator()\n",
        "    next_element = iterator.get_next()\n",
        "    batch = sess.run(next_element)\n",
        "\n",
        "    feed_dictionary = {placeholders_tensors['x']: np.array(normalize(batch['image'][:count])),\n",
        "                       placeholders_tensors['y']: np.array(get_one_hot(batch['label'][:count])),\n",
        "                       placeholders_tensors['dropout_rate']: [0, 0]}\n",
        "    probs = sess.run(placeholders_tensors['probs'], feed_dict = feed_dictionary)\n",
        "    predicted_label = np.argmax(probs, 1)\n",
        "    feed_dictionary = {placeholders_tensors['x']: np.array(normalize(batch['image'][:count])),\n",
        "                       placeholders_tensors['y']: np.array(get_one_hot(predicted_label)),\n",
        "                       placeholders_tensors['dropout_rate']: [0, 0]}\n",
        "    grad_cam = sess.run(placeholders_tensors['grad_cam'], feed_dict = feed_dictionary)\n",
        "\n",
        "    return np.array(batch['image']), grad_cam, probs, np.array(batch['label'])"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ncn0uE4Wkpke"
      },
      "source": [
        "def visualisation(sess, placeholders_tensors, dataset, labels, count):\n",
        "    # visualise some images and their grad-cam heatmap\n",
        "    images, grad_cams, probs, ground_truths = get_results_for_visualization(sess,\n",
        "                                                                            placeholders_tensors,\n",
        "                                                                            dataset, count)\n",
        "\n",
        "    _, axes = plt.subplots(figsize = [8, 2 * count], nrows = count,\n",
        "                           ncols = 4, sharey = True, sharex = True)\n",
        "\n",
        "    for idx in list(range(count)):\n",
        "        grad_cam = grad_cams[idx] / np.max(grad_cams[idx]) # normalize\n",
        "        grad_cam = resize(grad_cam, (config['height'], config['width']),\n",
        "                          preserve_range = True, mode = 'constant')\n",
        "        grad_cam_heatmap = cv2.applyColorMap(np.uint8(255.0 * grad_cam), cv2.COLORMAP_JET)\n",
        "        grad_cam_heatmap = cv2.cvtColor(grad_cam_heatmap, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "        image = normalize(images[idx]).reshape(config['height'],\n",
        "                                               config['width'],\n",
        "                                               config['num_channels'])\n",
        "        max_prob_idx = np.argmax(probs[idx])\n",
        "        ground_truth = ground_truths[idx]\n",
        "        pred_Truth_labels = labels[max_prob_idx] + \" / \" + labels[ground_truth]\n",
        "\n",
        "        axes[idx, 0].imshow(image)\n",
        "        axes[idx, 0].set_title('Input Image')\n",
        "        axes[idx, 0].axis('off')\n",
        "        axes[idx, 1].imshow(grad_cam_heatmap)\n",
        "        axes[idx, 1].set_title('Grad_CAM')\n",
        "        axes[idx, 1].axis('off')\n",
        "        axes[idx, 2].imshow(image)\n",
        "        axes[idx, 2].imshow(grad_cam_heatmap, alpha = 0.5)\n",
        "        axes[idx, 2].set_title('Overlayed')\n",
        "        axes[idx, 2].axis('off')\n",
        "        axes[idx, 3].imshow(np.ones_like(image), alpha = 0.0)\n",
        "        axes[idx, 3].text(5, 16, pred_Truth_labels, color = 'white', fontsize = 15)\n",
        "        axes[idx, 3].set_title('Prediction / GroundTruth')\n",
        "        axes[idx, 3].axis('off')\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rjS7PE6ykpke"
      },
      "source": [
        "# Train Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V9Lk7vbpkpke"
      },
      "source": [
        "def save_model_on_imporvemnet(file_path, sess, cv_acc, cv_accs):\n",
        "  #  save model when there is improvemnet in cv_acc value\n",
        "    if cv_accs == [] or cv_acc > np.max(cv_accs):\n",
        "        saver = tf.train.Saver(max_to_keep = 1)\n",
        "        saver.save(sess, file_path)\n",
        "        print('Model saved')\n",
        "        return True\n",
        "    print('')\n",
        "    return False"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nMO7K5onkpkf"
      },
      "source": [
        "def log_loss_acc(file_path, epoch, train_loss, train_acc,\n",
        "                 cv_loss, cv_acc, log_mode = 'a'):\n",
        "    # log train and cv losses as well as accuracy\n",
        "    mode = log_mode if epoch == 0 else 'a'\n",
        "\n",
        "    with open(file_path, mode) as f:\n",
        "        if mode == 'w':\n",
        "            header = 'epoch, train_loss, train_acc, cv_loss, cv_acc\\n'\n",
        "            f.write(header)\n",
        "\n",
        "        line = '%d, %f, %f, %f, %f\\n' %(epoch, train_loss, train_acc, cv_loss, cv_acc)\n",
        "        f.write(line)"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CKzwZaYpkpkf"
      },
      "source": [
        "def train_per_epoch(sess, dataset, placeholders_tensors, epoch, train_batches_count):\n",
        "    # one epoch of training\n",
        "    # loss and accuracy are returned\n",
        "    tmp_loss, tmp_acc = [], []\n",
        "    t_total = 0\n",
        "\n",
        "    iterator = dataset.make_one_shot_iterator()\n",
        "    next_element = iterator.get_next()\n",
        "    for iteration in range(train_batches_count):\n",
        "        t_start = time.time()\n",
        "        batch = sess.run(next_element)\n",
        "        feed_dictionary = {placeholders_tensors['x']: np.array(normalize(batch['image'])),\n",
        "                           placeholders_tensors['y']: np.array(get_one_hot(batch['label'])),\n",
        "                           placeholders_tensors['dropout_rate']: config['dropout_rate']}\n",
        "\n",
        "        sess.run(placeholders_tensors['optimizer'], feed_dict = feed_dictionary)\n",
        "        train_loss = sess.run(placeholders_tensors['loss'], feed_dict = feed_dictionary)\n",
        "        train_acc = sess.run(placeholders_tensors['acc'], feed_dict = feed_dictionary)\n",
        "        tmp_loss.append(train_loss)\n",
        "        tmp_acc.append(train_acc)\n",
        "        t_total += (time.time() - t_start)\n",
        "        print(' '*60, end = '\\r')\n",
        "        print('epoch: %d, time: %f | train_loss: %f | acc: %f' %(epoch, t_total, train_loss,\n",
        "                                                                 train_acc), end = '\\r')\n",
        "    train_loss = np.mean(tmp_loss)\n",
        "    train_acc = np.mean(tmp_acc)\n",
        "    print(' '*60, end = '\\r')\n",
        "    print('epoch: %d, time: %f | train_loss: %f | acc: %f\\n' %(epoch, t_total, train_loss,\n",
        "                                                               train_acc), end = '\\r')\n",
        "    return train_loss, train_acc"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pVHCH4k3kpkf"
      },
      "source": [
        "def cv_per_epoch(sess, dataset, placeholders_tensors, epoch, cv_batches_count):\n",
        "    # cross-validation per epoch\n",
        "    # cv_loss and cv_accuracy are returned\n",
        "    tmp_loss, tmp_acc = [], []\n",
        "    t_total = 0\n",
        "\n",
        "    iterator = dataset.make_one_shot_iterator()\n",
        "    next_element = iterator.get_next()\n",
        "    for iteration in range(cv_batches_count):\n",
        "        t_start = time.time()\n",
        "        batch = sess.run(next_element)\n",
        "        cv_feed_dictionary = {placeholders_tensors['x']: np.array(normalize(batch['image'])),\n",
        "                              placeholders_tensors['y']: np.array(get_one_hot(batch['label'])),\n",
        "                              placeholders_tensors['dropout_rate']: [0, 0]}\n",
        "\n",
        "        cv_loss = sess.run(placeholders_tensors['loss'], feed_dict = cv_feed_dictionary)\n",
        "        cv_acc = sess.run(placeholders_tensors['acc'], feed_dict = cv_feed_dictionary)\n",
        "\n",
        "        tmp_loss.append(cv_loss)\n",
        "        tmp_acc.append(cv_acc)\n",
        "        t_total += (time.time() - t_start)\n",
        "        print(' '*60, end = '\\r')\n",
        "        print('          cv_time: %f | cv_loss: %f | cv_acc: %f' %(t_total, cv_loss,\n",
        "                                                                   cv_acc), end = '\\r')\n",
        "    cv_loss = np.mean(tmp_loss)\n",
        "    cv_acc = np.mean(tmp_acc)\n",
        "    print(' '*60, end = '\\r')\n",
        "    print('          cv_time: %f | cv_loss: %f | cv_acc: %f\\n' %(t_total, cv_loss,\n",
        "                                                                 cv_acc), end = '\\r')\n",
        "    return cv_loss, cv_acc"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pwofRDnPkpkf"
      },
      "source": [
        "def train_model(batch_size, epochs, resume, conv_layer_vis_index = -1):\n",
        "    # train CNN model\n",
        "    init_epoch = 0\n",
        "    train_losses, cv_losses = [], []\n",
        "    train_accs, cv_accs = [], []\n",
        "    ops.reset_default_graph()\n",
        "    placeholders_tensors = get_placeholders_tensors(target_layer_index = conv_layer_vis_index)\n",
        "\n",
        "    with tf.Session() as sess:\n",
        "        if resume:\n",
        "            print('loading weights....')\n",
        "            saver = tf.train.Saver()\n",
        "            saver.restore(sess, (config['model_path']))  # to load the best saved model\n",
        "            # load saved losses and accuracies so that less accurate model\n",
        "            # won't be saved after resume\n",
        "            tmp = np.genfromtxt(config['log_path'], delimiter = ',', names = True)\n",
        "            train_losses = list(tmp['train_loss'])\n",
        "            train_accs = list(tmp['train_acc'])\n",
        "            cv_losses = list(tmp['cv_loss'])\n",
        "            cv_accs = list(tmp['cv_acc'])\n",
        "            init_epoch  = len(train_losses)\n",
        "            del tmp\n",
        "        else:\n",
        "            print('initializing weights....')\n",
        "            init_op = tf.group(tf.local_variables_initializer(), tf.global_variables_initializer())\n",
        "            sess.run(init_op)\n",
        "\n",
        "        print('training....')\n",
        "        dataset, dataset_count, labels = get_data(batch_size)\n",
        "        train_batch_count = int(dataset_count[0] / batch_size) + 1\n",
        "        cv_batch_count = int(dataset_count[1] / batch_size) + 1\n",
        "        for epoch in range(init_epoch, init_epoch + epochs):\n",
        "            # training\n",
        "            train_loss, train_acc = train_per_epoch(sess, dataset[0],\n",
        "                                                    placeholders_tensors, epoch, train_batch_count)\n",
        "            train_losses.append(train_loss)\n",
        "            train_accs.append(train_acc)\n",
        "\n",
        "            # cross-validation\n",
        "            cv_loss, cv_acc = cv_per_epoch(sess, dataset[1],\n",
        "                                           placeholders_tensors, epoch, cv_batch_count)\n",
        "            # save model\n",
        "            is_saved = save_model_on_imporvemnet(config['model_path'], sess, cv_acc, cv_accs)\n",
        "            cv_losses.append(cv_loss)\n",
        "            cv_accs.append(cv_acc)\n",
        "            # log results\n",
        "            log_loss_acc(config['log_path'], epoch, train_loss, train_acc, cv_loss, cv_acc,\n",
        "                         log_mode = ('a' if resume else 'w'))\n",
        "            # visualization\n",
        "            if is_saved:\n",
        "                visualisation(sess, placeholders_tensors, dataset[1], labels, 4)\n",
        "        return train_losses, cv_losses, train_accs, cv_accs"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "-OTJuc-vkpkf",
        "outputId": "a7f046f7-297b-40f4-948c-820eecdbab3b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        }
      },
      "source": [
        "loss_acc = train_model(256, 300, False, -1)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-38-0c3984258b69>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mloss_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m300\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-37-f2e04ec05e7e>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(batch_size, epochs, resume, conv_layer_vis_index)\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mtrain_accs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv_accs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_default_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mplaceholders_tensors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_placeholders_tensors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget_layer_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconv_layer_vis_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-27-7b4d305f10ca>\u001b[0m in \u001b[0;36mget_placeholders_tensors\u001b[0;34m(target_layer_index)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;31m# get model's placeholders and tensors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;31m# target_layer_index is the index of the conv layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     x = tf.placeholder(tf.float32, name = 'x', shape = [None,\n\u001b[0m\u001b[1;32m      5\u001b[0m                                                         \u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'height'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m                                                         \u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'width'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: module 'tensorflow' has no attribute 'placeholder'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FgP25KOqkpkg"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}